{
    "pdf_path": [
        "C:\\BLS\\EvalAI5\\Uploads\\XGBoost.pdf"
    ],
    "pdf_hash": "fb03a859b77ba04ac1a2d395e71ff73851716a4d8e083f9efd483d29f8523d4b",
    "quiz": [
        {
            "question": "What technique does xgboost incorporate in its implementation?",
            "options": {
                "A": "Random Forest",
                "B": "Gradient Boosting",
                "C": "Decision Trees",
                "D": "Support Vector Machines"
            },
            "correct_answer": "B",
            "explanation": "XGBoost is a popular implementation of gradient boosting, which is a machine learning technique for regression and classification tasks.",
            "type": "MCQ",
            "id": "q_0"
        },
        {
            "question": "What is the term for the maximum number of features that can be considered at each split in a tree?",
            "options": {
                "A": "Max Depth",
                "B": "Max Features",
                "C": "Min Samples Split",
                "D": "Min Samples Leaf"
            },
            "correct_answer": "B",
            "explanation": "Max features is a hyperparameter in tree algorithms that controls the maximum number of features considered at each split.",
            "type": "MCQ",
            "id": "q_1"
        },
        {
            "question": "What is the role of regularization in a tree-based algorithm?",
            "answer": "It prevents overfitting by penalizing complex models.",
            "explanation": "Regularization in a tree-based algorithm prevents overfitting by penalizing complex models and promoting simpler ones.",
            "type": "SAQ",
            "id": "q_2"
        },
        {
            "question": "What is the significance of the algorithm tree in a tree-based algorithm?",
            "answer": "It determines the structure of the tree and its decision-making process.",
            "explanation": "The algorithm tree in a tree-based algorithm determines the structure of the tree and its decision-making process.",
            "type": "SAQ",
            "id": "q_3"
        },
        {
            "question": "What is the purpose of model tuning in xgboost?",
            "options": {
                "A": "To improve model interpretability",
                "B": "To reduce model complexity",
                "C": "To optimize model hyperparameters",
                "D": "To increase model training speed"
            },
            "correct_answer": "C",
            "explanation": "Model tuning in xgboost involves adjusting hyperparameters to optimize the model's performance on a given dataset.",
            "type": "MCQ",
            "id": "q_4"
        },
        {
            "question": "What is the value that requires trees in a tree-based algorithm?",
            "answer": "The minimum number of samples required to split an internal node.",
            "explanation": "The minimum number of samples required to split an internal node is a critical value that determines the structure of the tree in a tree-based algorithm.",
            "type": "SAQ",
            "id": "q_5"
        },
        {
            "question": "What techniques does xgboost incorporate?",
            "answer": "Gradient boosting, parallelization, and model tuning.",
            "explanation": "XGBoost incorporates various techniques to improve its performance, including gradient boosting, parallelization, and model tuning.",
            "type": "SAQ",
            "id": "q_6"
        },
        {
            "question": "What is the purpose of validation in model tuning?",
            "answer": "To evaluate the model's performance on unseen data.",
            "explanation": "Validation in model tuning involves evaluating the model's performance on unseen data to prevent overfitting.",
            "type": "SAQ",
            "id": "q_7"
        },
        {
            "question": "What is the term for the process of adjusting tree-specific parameters in xgboost?",
            "options": {
                "A": "Boosting Rounds",
                "B": "Tree Pruning",
                "C": "Tree Tuning",
                "D": "Tree Specific Tuning"
            },
            "correct_answer": "C",
            "explanation": "Tree tuning in xgboost involves adjusting parameters specific to each tree in the ensemble to improve overall model performance.",
            "type": "MCQ",
            "id": "q_8"
        },
        {
            "question": "What is the primary use of xgboost in datasets?",
            "answer": "To train models quickly.",
            "explanation": "XGBoost is designed to train models quickly on large datasets.",
            "type": "SAQ",
            "id": "q_9"
        },
        {
            "question": "What is the purpose of model tuning in xgboost?",
            "answer": "To optimize hyperparameters for better performance.",
            "explanation": "Model tuning in xgboost involves adjusting hyperparameters to improve the model's performance.",
            "type": "SAQ",
            "id": "q_10"
        },
        {
            "question": "What is classifier parameter tuning?",
            "answer": "The process of adjusting model parameters to improve classification accuracy.",
            "explanation": "Classifier parameter tuning involves adjusting model parameters to improve classification accuracy.",
            "type": "SAQ",
            "id": "q_11"
        },
        {
            "question": "What is the effect of tree pruning on sparsity in a tree-based algorithm?",
            "answer": "It reduces the number of leaves and increases sparsity.",
            "explanation": "Tree pruning in a tree-based algorithm reduces the number of leaves and increases sparsity by removing unnecessary nodes.",
            "type": "SAQ",
            "id": "q_12"
        },
        {
            "question": "What are xgboost hyperparameters?",
            "answer": "Parameters that control the model's behavior, such as learning rate and max depth.",
            "explanation": "XGBoost hyperparameters are parameters that control the model's behavior and need to be tuned for optimal performance.",
            "type": "SAQ",
            "id": "q_13"
        },
        {
            "question": "What is the purpose of tuning a specific tree in a tree-based algorithm?",
            "answer": "To optimize its performance and reduce overfitting.",
            "explanation": "Tuning a specific tree in a tree-based algorithm involves adjusting its parameters to optimize its performance and reduce overfitting.",
            "type": "SAQ",
            "id": "q_14"
        },
        {
            "question": "What is the purpose of regularization in the context of tree algorithms?",
            "options": {
                "A": "To reduce overfitting",
                "B": "To increase model complexity",
                "C": "To improve model interpretability",
                "D": "To decrease model accuracy"
            },
            "correct_answer": "A",
            "explanation": "Regularization in tree algorithms, such as xgboost, helps to prevent overfitting by penalizing complex models.",
            "type": "MCQ",
            "id": "q_15"
        },
        {
            "question": "What is the significance of parallelization in xgboost?",
            "answer": "It speeds up the training process by utilizing multiple cores.",
            "explanation": "Parallelization in xgboost allows it to take advantage of multi-core processors, speeding up the training process.",
            "type": "SAQ",
            "id": "q_16"
        },
        {
            "question": "What is the relationship between scala and hadoop in xgboost?",
            "answer": "Scala is used for development, and hadoop is used for distributed computing.",
            "explanation": "Scala is used for developing xgboost, while hadoop is used for distributed computing to handle large datasets. **Theme_2: Tree-based Algorithms**",
            "type": "SAQ",
            "id": "q_17"
        },
        {
            "question": "What is the primary advantage of using xgboost for large datasets?",
            "options": {
                "A": "Faster model training",
                "B": "Better model interpretability",
                "C": "Improved model accuracy",
                "D": "Easier model deployment"
            },
            "correct_answer": "A",
            "explanation": "XGBoost is designed to handle large datasets quickly, making it an ideal choice for big data applications.",
            "type": "MCQ",
            "id": "q_18"
        },
        {
            "question": "What is the effect of boosting rounds on trees in a tree-based algorithm?",
            "answer": "It increases the model's complexity and reduces overfitting.",
            "explanation": "Boosting rounds in a tree-based algorithm increase the model's complexity and reduce overfitting by combining the predictions of multiple trees.",
            "type": "SAQ",
            "id": "q_19"
        }
    ],
    "created_at": "2025-12-29 11:00:43.775923"
}